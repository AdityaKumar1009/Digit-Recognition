{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Handwritten Digit Recognition using Neural Network\n", "This notebook implements a simple neural network from scratch to classify handwritten digits (0-9) using the MNIST dataset.\n", "We will use **NumPy** for matrix operations and **Matplotlib** for visualization."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary libraries\n", "import numpy as np\n", "import pandas as pd\n", "from matplotlib import pyplot as plt\n", "\n", "# Load the dataset (MNIST Handwritten Digits)\n", "data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n", "data = np.array(data)\n", "m, n = data.shape  # m = total samples, n = features + label\n", "\n", "# Shuffle the data to randomize training and development sets\n", "np.random.shuffle(data)  \n", "\n", "# Split into development and training sets\n", "data_dev = data[0:1000].T  # First 1000 samples for development (testing)\n", "Y_dev = data_dev[0]  # Labels\n", "X_dev = data_dev[1:n] / 255.  # Normalize pixel values (0-255 -> 0-1)\n", "\n", "data_train = data[1000:m].T  # Remaining for training\n", "Y_train = data_train[0]\n", "X_train = data_train[1:n] / 255.\n", "\n", "_, m_train = X_train.shape  # Number of training samples\n", "print(\"Training Data Shape:\", X_train.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Initialize Neural Network Parameters\n", "The neural network consists of:\n", "- **Input Layer (784 neurons)**: Each digit is a 28x28 image, flattened to 784 pixels.\n", "- **Hidden Layer (10 neurons)**: Using ReLU activation.\n", "- **Output Layer (10 neurons)**: Using Softmax activation (for 10 classes: digits 0-9)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def init_params():\n", "    \"\"\"Initialize weights and biases with small random values.\"\"\"\n", "    W1 = np.random.rand(10, 784) - 0.5  # Hidden layer weights\n", "    b1 = np.random.rand(10, 1) - 0.5  # Hidden layer bias\n", "    W2 = np.random.rand(10, 10) - 0.5  # Output layer weights\n", "    b2 = np.random.rand(10, 1) - 0.5  # Output layer bias\n", "    return W1, b1, W2, b2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Activation Functions\n", "- **ReLU (Rectified Linear Unit)**: For hidden layer activation.\n", "- **Softmax**: Converts output into probabilities."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ReLU(Z):\n", "    return np.maximum(Z, 0)  # ReLU activation\n", "\n", "def softmax(Z):\n", "    return np.exp(Z) / np.sum(np.exp(Z), axis=0, keepdims=True)  # Softmax activation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Forward Propagation\n", "Computes activations for each layer using the initialized parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def forward_prop(W1, b1, W2, b2, X):\n", "    Z1 = W1.dot(X) + b1\n", "    A1 = ReLU(Z1)\n", "    Z2 = W2.dot(A1) + b2\n", "    A2 = softmax(Z2)\n", "    return Z1, A1, Z2, A2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Backward Propagation\n", "Computes gradients and updates weights using gradient descent."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n", "    one_hot_Y = np.eye(10)[Y].T  # Convert labels to one-hot encoding\n", "    \n", "    dZ2 = A2 - one_hot_Y  # Error in output layer\n", "    dW2 = 1 / m_train * dZ2.dot(A1.T)\n", "    db2 = 1 / m_train * np.sum(dZ2, axis=1, keepdims=True)\n", "    dZ1 = W2.T.dot(dZ2) * (Z1 > 0)  # ReLU derivative\n", "    dW1 = 1 / m_train * dZ1.dot(X.T)\n", "    db1 = 1 / m_train * np.sum(dZ1, axis=1, keepdims=True)\n", "    \n", "    return dW1, db1, dW2, db2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training the Neural Network\n", "Using **gradient descent** to update weights iteratively."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def gradient_descent(X, Y, alpha, iterations):\n", "    W1, b1, W2, b2 = init_params()\n", "    for i in range(iterations):\n", "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n", "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n", "        W1 -= alpha * dW1\n", "        b1 -= alpha * db1\n", "        W2 -= alpha * dW2\n", "        b2 -= alpha * db2\n", "        if i % 10 == 0:\n", "            print(\"Iteration:\", i, \"Accuracy:\", np.mean(np.argmax(A2, axis=0) == Y))\n", "    return W1, b1, W2, b2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training the Model\n", "We train the neural network using gradient descent for 500 iterations with a learning rate of 0.1."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train the model\n", "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, alpha=0.1, iterations=500)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Testing the Model\n", "We define functions to make predictions and evaluate accuracy."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def make_predictions(X, W1, b1, W2, b2):\n", "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n", "    return np.argmax(A2, axis=0)  # Get predicted labels\n", "\n", "def get_accuracy(predictions, Y):\n", "    return np.sum(predictions == Y) / Y.size  # Compute accuracy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Evaluate on Training Set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_predictions = make_predictions(X_train, W1, b1, W2, b2)\n", "train_accuracy = get_accuracy(train_predictions, Y_train)\n", "print(\"Training Accuracy:\", train_accuracy)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Evaluate on Development (Testing) Set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n", "dev_accuracy = get_accuracy(dev_predictions, Y_dev)\n", "print(\"Development Set Accuracy:\", dev_accuracy)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualizing a Prediction\n", "We can visualize a sample prediction from the development set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_prediction(index, W1, b1, W2, b2):\n", "    current_image = X_dev[:, index, None]\n", "    prediction = make_predictions(current_image, W1, b1, W2, b2)\n", "    label = Y_dev[index]\n", "    \n", "    print(\"Prediction:\", prediction)\n", "    print(\"Label:\", label)\n", "    \n", "    current_image = current_image.reshape((28, 28)) * 255  # Reshape and scale image\n", "    plt.gray()\n", "    plt.imshow(current_image, interpolation='nearest')\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Test with a random image\n", "test_prediction(0, W1, b1, W2, b2)  # Change index to test different images"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 4}